{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import getpass\n",
    "import base64\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "import operator\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools import GooglePlacesTool\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Set API Keys (temp)\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = getpass.getpass(\"Enter your Langchain API key: \")\n",
    "os.environ['TAVILY_API_KEY'] = getpass.getpass(\"Enter your Tavily API key: \")\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"GPLACES_API_KEY\"] = getpass.getpass(\"Enter your Google Places API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prompt = \"Only return a valid json string (RCF8259). Do provide any other commentary. Do not wrap the JSON in markdown such as ```json. Only use the data from the provided content.\"\n",
    "\n",
    "prompt_template = \"\"\"USER: Given a set of streetview images from a vehicle, your task is to determine the\n",
    "coordinates from which the picture was taken. It can be anywhere in the world.\n",
    "\n",
    "Return json with the city and coordinates following the below example. {json_prompt}\n",
    "output={{\"city\": \"Orland Park, IL, 60467, USA\", \"latitude\": \"42.0099\", \"longitude\": \"-87.62317\"}}\n",
    "\n",
    "AGENT: output=\"\"\"\n",
    "\n",
    "text_prompt = prompt_template.format(json_prompt=json_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search tool\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "places_tool = GooglePlacesTool()\n",
    "tools = [search_tool, places_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "# Define nodes\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there are no tool calls, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8Kk25mBIUADuc8vkCYyhyqKh', 'function': {'arguments': '{\"query\": \"La Poste, Bouygues Immobilier\"}', 'name': 'google_places'}, 'type': 'function'}, {'id': 'call_MJNH6IjenHEMnmpWOqIDLRJE', 'function': {'arguments': '{\"query\": \"La Poste, Bouygues Immobilier\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 6029, 'total_tokens': 6091}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_3196d36131', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d109e3b9-6b8e-403d-8175-76d242a4e806-0', tool_calls=[{'name': 'google_places', 'args': {'query': 'La Poste, Bouygues Immobilier'}, 'id': 'call_8Kk25mBIUADuc8vkCYyhyqKh'}, {'name': 'tavily_search_results_json', 'args': {'query': 'La Poste, Bouygues Immobilier'}, 'id': 'call_MJNH6IjenHEMnmpWOqIDLRJE'}])]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'action':\n",
      "---\n",
      "{'messages': [ToolMessage(content='1. Bouygues Immobilier\\nAddress: ZAC des Linandes, 33 Av. de la Plaine des Sports, 95800 Cergy, France\\nGoogle place ID: ChIJ2xuJZO315kcRCwWzG2XEWps\\nPhone: 01 55 38 25 25\\nWebsite: https://www.bouygues-immobilier.com/nos-espaces-de-vente/espace-de-vente-cergy\\n\\n', name='google_places', tool_call_id='call_8Kk25mBIUADuc8vkCYyhyqKh'), ToolMessage(content='[{\"url\": \"https://laposteimmobilier.fr/actualites/communique-poste-immo-lance-une-premiere-serie-de-residences-services-seniors\", \"content\": \"Poste Immo, la filiale immobili\\\\u00e8re du Groupe La Poste, va lancer une premi\\\\u00e8re s\\\\u00e9rie de R\\\\u00e9sidences Services Seniors (RSS) \\\\u00e0 horizon 2022-2024, en partenariat avec Les Jardins d\\'Arcadie, Acapace et Bouygues Immobilier. Brest, Ch\\\\u00e2teauroux, St-Etienne, Auch, Villefranche-de-Rouergue et Amiens feront partie des premi\\\\u00e8res r\\\\u00e9alisations.\"}, {\"url\": \"https://www.bouygues-immobilier-corporate.com/references/lhotel-des-postes\", \"content\": \"L\\'H\\\\u00f4tel des Postes. Au c\\\\u0153ur de la Neustadt, quartier de Strasbourg class\\\\u00e9 au patrimoine mondial de l\\'UNESCO, L\\'H\\\\u00f4tel des Postes accueillera des logements, des bureaux neufs et r\\\\u00e9habilit\\\\u00e9s, une r\\\\u00e9sidences services seniors, une brasserie-restaurant, ainsi qu\\'un bureau de poste (sur une surface de pr\\\\u00e8s de 20 000 m\\\\u00b2). cr\\\\u00e9dit LD3D.\"}, {\"url\": \"https://www.bouygues-immobilier-corporate.com/sites/default/files/press-release/2023-06/Communiqu\\\\u00e9 de Presse - H\\\\u00f4tel des Postes Strasbourg.pdf\", \"content\": \"L\\'H\\\\u00f4tel des Postes est l\\'un des projets les plus embl\\\\u00e9matiques de Bouygues Immobilier car il met en valeur toute la richesse des offres propos\\\\u00e9es par Bouygues Immobilier ainsi que son expertise en mati\\\\u00e8re de r\\\\u00e9habilitation et de transformation, notamment de bureaux en logements .\"}]', name='tavily_search_results_json', tool_call_id='call_MJNH6IjenHEMnmpWOqIDLRJE')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='{\\n  \"city\": \"Cergy, France\",\\n  \"latitude\": \"49.0365\",\\n  \"longitude\": \"2.0626\"\\n}', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 6668, 'total_tokens': 6701}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_3196d36131', 'finish_reason': 'stop', 'logprobs': None}, id='run-d3e3a1c6-93dc-4fb4-bb71-958a46b01646-0')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "  \n",
    "# Path to your image\n",
    "id = \"103\"\n",
    "image_dir = f'./data/{id}/'\n",
    "directions = [\"north\", \"south\", \"east\", \"west\"]\n",
    "image_inputs = []\n",
    "for direction in directions:\n",
    "    base64_img = encode_image(f\"{image_dir}{direction}.png\")\n",
    "    image_input = {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img}\"}}\n",
    "    image_inputs.append(image_input)\n",
    "\n",
    "# Define input\n",
    "text_input = [{\"type\": \"text\", \"text\": text_prompt}]\n",
    "inputs = {\"messages\": [HumanMessage(content=text_input + image_inputs)]}\n",
    "\n",
    "# Run app with streaming\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'Cergy, France', 'latitude': '49.0365', 'longitude': '2.0626'}\n"
     ]
    }
   ],
   "source": [
    "# Get content from AIMessage\n",
    "result = json.loads(output[\"agent\"][\"messages\"][0].content)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
